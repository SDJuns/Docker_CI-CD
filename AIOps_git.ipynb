{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "from pyngrok import ngrok\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import os\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"/Users/sindongjun/AIOpsNLP/mlflow_logs\")  # Google Drive에 저장\n",
    "mlflow.set_experiment(\"AIOPS_v1.2\")  # 실험 이름 설정\n",
    "RUN_NAME = 'EfficientNet-B0_base'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'LR' : 0.1e-3,\n",
    "          'BATCH_SIZE' : 32,\n",
    "          'EPOCH' : 10,\n",
    "          'TRAIN_RATIO': 0.8,\n",
    "          'LR_STEP' : 3,\n",
    "          'LR_GAMMA' : 0.9\n",
    "          }\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_type = 'efficientnetb0'\n",
    "path = '/Users/sindongjun/AIOpsNLP/Data'\n",
    "save_model_path = os.path.join(path, f'results/{model_type}.pth')\n",
    "save_history_path = os.path.join(path, f'results/{model_type}_history.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 커스텀 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 960\n",
      "Validation size: 120\n",
      "Test size: 120\n",
      "Batch image type: <class 'torch.Tensor'>, shape: torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# CustomOrderImageFolder: ImageFolder를 상속받아 custom_order를 적용하는 클래스\n",
    "class CustomOrderImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None, target_transform=None, custom_order=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): 이미지가 저장된 최상위 경로.\n",
    "            transform (callable, optional): 이미지 변환.\n",
    "            target_transform (callable, optional): 레이블 변환.\n",
    "            custom_order (list, optional): 원하는 클래스 순서의 리스트.\n",
    "        \"\"\"\n",
    "        self.custom_order = custom_order\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "    def find_classes(self, directory):\n",
    "        # 폴더 내의 클래스(폴더) 이름을 추출\n",
    "        if self.custom_order is not None:\n",
    "            classes = self.custom_order\n",
    "        else:\n",
    "            classes = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "            classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "# CustomSubset: 기본 ImageFolder (CustomOrderImageFolder)에서 인덱스별로 데이터를 로드하며, 개별 transform을 적용하는 Dataset 클래스\n",
    "class CustomSubset(Dataset):\n",
    "    def __init__(self, image_folder, indices, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_folder (ImageFolder): 기본 이미지 데이터셋 (transform=None이어야 함)\n",
    "            indices (list or array): 선택할 데이터 인덱스 목록\n",
    "            transform (callable): 해당 데이터셋에 적용할 transform\n",
    "        \"\"\"\n",
    "        self.image_folder = image_folder\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 실제 인덱스\n",
    "        actual_idx = self.indices[idx]\n",
    "        # image_folder.samples는 (path, label) 튜플의 리스트\n",
    "        path, label = self.image_folder.samples[actual_idx]\n",
    "        # image_folder.loader는 PIL.Image로 이미지를 로드하는 함수\n",
    "        image = self.image_folder.loader(path)\n",
    "        # 지정된 transform을 적용하여 Tensor로 변환 (또는 다른 변환)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def get_dataloaders(train_dataset, val_dataset, BATCH_SIZE):\n",
    "    train_DL = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_DL = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    return train_DL, val_DL\n",
    "\n",
    "custom_order = ['양호', '경증', '중등도', '중증']\n",
    "\n",
    "# 기본 dataset은 transform 없이 생성 (순서 유지를 위해)\n",
    "base_dataset = CustomOrderImageFolder(root=os.path.join(path, 'data'),\n",
    "                                        transform=None,\n",
    "                                        custom_order=custom_order)\n",
    "\n",
    "# 전체 데이터셋의 레이블 목록 생성\n",
    "targets = np.array([label for _, label in base_dataset.samples])\n",
    "\n",
    "# 전체 데이터를 train (80%)와 test+val (20%)로 stratified split\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_idx, test_val_idx in sss1.split(np.zeros(len(targets)), targets):\n",
    "    pass\n",
    "\n",
    "# test+val 셋을 50:50 비율로 분할하여 validation (10%)과 test (10%) 데이터셋 생성\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "test_val_targets = targets[test_val_idx]\n",
    "for val_rel_idx, test_rel_idx in sss2.split(np.zeros(len(test_val_targets)), test_val_targets):\n",
    "    val_idx = test_val_idx[val_rel_idx]\n",
    "    test_idx = test_val_idx[test_rel_idx]\n",
    "    break\n",
    "\n",
    "# 각 데이터셋마다 적용할 transform 정의\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# CustomSubset을 이용해 각 데이터셋 생성 (각각 다른 transform 적용)\n",
    "train_dataset = CustomSubset(base_dataset, train_idx, transform=train_transform)\n",
    "val_dataset   = CustomSubset(base_dataset, val_idx, transform=val_transform)\n",
    "test_dataset  = CustomSubset(base_dataset, test_idx, transform=test_transform)\n",
    "\n",
    "# DataLoader 생성 (num_workers=0으로 하여 멀티프로세싱 문제 배제)\n",
    "train_DL, val_DL = get_dataloaders(train_dataset, val_dataset, params['BATCH_SIZE'])\n",
    "test_DL  = DataLoader(test_dataset, batch_size=params['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Validation size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n",
    "\n",
    "# 한 배치를 불러와서 확인 (모든 이미지가 Tensor로 변환되었는지 확인)\n",
    "for images, labels in train_DL:\n",
    "    print(f\"Batch image type: {type(images)}, shape: {images.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "second_model_path = '/Users/sindongjun/AIOpsNLP/final_best_model.pth'\n",
    "\n",
    "load_model = torch.load(second_model_path, map_location=DEVICE, weights_only=False)['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "# # 기존 ngrok 세션 종료\n",
    "ngrok.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow UI에 접속하려면 다음 링크를 클릭하세요: NgrokTunnel: \"https://c86d-61-34-253-239.ngrok-free.app\" -> \"http://localhost:5001\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-26 17:37:30 +0900] [10547] [INFO] Starting gunicorn 23.0.0\n",
      "[2025-05-26 17:37:30 +0900] [10547] [ERROR] Connection in use: ('127.0.0.1', 5001)\n",
      "[2025-05-26 17:37:30 +0900] [10547] [ERROR] connection to ('127.0.0.1', 5001) failed: [Errno 48] Address already in use\n",
      "[2025-05-26 17:37:31 +0900] [10547] [ERROR] Connection in use: ('127.0.0.1', 5001)\n",
      "[2025-05-26 17:37:31 +0900] [10547] [ERROR] connection to ('127.0.0.1', 5001) failed: [Errno 48] Address already in use\n",
      "[2025-05-26 17:37:32 +0900] [10547] [ERROR] Connection in use: ('127.0.0.1', 5001)\n",
      "[2025-05-26 17:37:32 +0900] [10547] [ERROR] connection to ('127.0.0.1', 5001) failed: [Errno 48] Address already in use\n",
      "[2025-05-26 17:37:33 +0900] [10547] [ERROR] Connection in use: ('127.0.0.1', 5001)\n",
      "[2025-05-26 17:37:33 +0900] [10547] [ERROR] connection to ('127.0.0.1', 5001) failed: [Errno 48] Address already in use\n",
      "[2025-05-26 17:37:34 +0900] [10547] [ERROR] Connection in use: ('127.0.0.1', 5001)\n",
      "[2025-05-26 17:37:34 +0900] [10547] [ERROR] connection to ('127.0.0.1', 5001) failed: [Errno 48] Address already in use\n",
      "[2025-05-26 17:37:35 +0900] [10547] [ERROR] Can't connect to ('127.0.0.1', 5001)\n",
      "Running the mlflow server failed. Please see the logs above for details.\n"
     ]
    }
   ],
   "source": [
    "# 2. MLflow UI 실행 (백그라운드 실행)\n",
    "get_ipython().system_raw(\"mlflow ui --backend-store-uri '//Users/sindongjun/AIOpsNLP/mlflow_logs' --port 5001 &\")\n",
    "\n",
    "# 3. ngrok을 이용해 터널링 (HTTP 방식으로 명시적으로 설정)\n",
    "public_url = ngrok.connect(5001, \"http\")\n",
    "print(f\"MLflow UI에 접속하려면 다음 링크를 클릭하세요: {public_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAST API 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrok.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (run):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/c5/3w490dqd0630nzl56hkxz6_r0000gn/T/ipykernel_10433/2525574917.py\", line 56, in run\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/uvicorn/main.py\", line 580, in run\n",
      "    server.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/uvicorn/server.py\", line 66, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/uvicorn/server.py\", line 70, in serve\n",
      "    await self._serve(sockets)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/uvicorn/server.py\", line 77, in _serve\n",
      "    config.load()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/uvicorn/config.py\", line 435, in load\n",
      "    self.loaded_app = import_from_string(self.app)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/uvicorn/importer.py\", line 19, in import_from_string\n",
      "    module = importlib.import_module(module_str)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"/Users/sindongjun/AIOpsNLP/Main.py\", line 16, in <module>\n",
      "    ckpt = torch.load('/Users/sindongjun/AIOpsNLP/model.pkl',\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py\", line 1425, in load\n",
      "    with _open_file_like(f, \"rb\") as opened_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py\", line 751, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py\", line 732, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/sindongjun/AIOpsNLP/model.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FastAPI URL: NgrokTunnel: \"https://b4a9-61-34-253-239.ngrok-free.app\" -> \"http://localhost:8000\"\n"
     ]
    }
   ],
   "source": [
    "# --- FastAPI 코드 저장 ---\n",
    "code = \"\"\"\n",
    "from fastapi import FastAPI, Request, UploadFile, File, Form\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fastapi.templating import Jinja2Templates\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from PIL import Image\n",
    "import torch, io\n",
    "from torchvision import transforms\n",
    "\n",
    "TEMPLATE_DIR = '/Users/sindongjun/AIOpsNLP'\n",
    "app = FastAPI()\n",
    "templates = Jinja2Templates(directory=TEMPLATE_DIR)\n",
    "\n",
    "# 구글 드라이브에 있는 templates 경로 지정\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ckpt = torch.load('/Users/sindongjun/AIOpsNLP/model.pkl',\n",
    "                  map_location=DEVICE, weights_only=False)\n",
    "model = ckpt['model'].to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "labels = ['양호', '경증', '중등도', '중증']\n",
    "\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def index(request: Request):\n",
    "    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n",
    "\n",
    "@app.post(\"/predict\", response_class=HTMLResponse)\n",
    "async def predict(request: Request, file: UploadFile = File(...)):\n",
    "    # 이미지 파일 읽기\n",
    "    contents = await file.read()\n",
    "    img = Image.open(io.BytesIO(contents)).convert('RGB')\n",
    "    x = preprocess(img).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        y = model(x).argmax(1).item()\n",
    "    y = 1  # 예시 (실제로는 모델로 예측)\n",
    "    pred_label = labels[y]\n",
    "    return templates.TemplateResponse(\"result.html\", {\"request\": request, \"prediction\": pred_label})\n",
    "\"\"\"\n",
    "with open('/Users/sindongjun/AIOpsNLP/Main.py', 'w') as f:\n",
    "    f.write(code)\n",
    "\n",
    "# --- 서버 & ngrok ---\n",
    "!pkill -f ngrok        # 터널 초기화\n",
    "\n",
    "import nest_asyncio, uvicorn, threading, time\n",
    "from pyngrok import ngrok\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def run():\n",
    "    uvicorn.run('Main:app', host='0.0.0.0', port=8000, reload=False)\n",
    "threading.Thread(target=run, daemon=True).start()\n",
    "time.sleep(2)\n",
    "\n",
    "public_url = ngrok.connect(8000)\n",
    "print('✅ FastAPI URL:', public_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ model.pkl 저장 완료:\n",
      "-rw-r--r--  1 sindongjun  staff    16M May 26 17:38 model.pkl\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ckpt_path = \"/Users/sindongjun/AIOpsNLP/final_best_model.pth\"\n",
    "\n",
    "# 1) .pth로부터 전체 모델 객체 복원\n",
    "ckpt = torch.load(ckpt_path, map_location=DEVICE, weights_only=False)\n",
    "model = ckpt[\"model\"].to(\"cpu\")   # 컨테이너에서 GPU 없을 수도 있으니 CPU로 저장\n",
    "model.eval()\n",
    "\n",
    "# 2) pickle로 덤프\n",
    "with open(\"/Users/sindongjun/AIOpsNLP/model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"✅ model.pkl 저장 완료:\" )\n",
    "!ls -lh model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "fastapi\n",
    "uvicorn[standard]\n",
    "pillow\n",
    "torch\n",
    "torchvision\n",
    "scikit-learn\n",
    "python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "# Dockerfile 예시\n",
    "FROM python:3.10-slim\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "CMD [\"uvicorn\", \"Main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: Main.py (deflated 46%)\n",
      "  adding: model.pkl (deflated 8%)\n",
      "  adding: requirements.txt (deflated 14%)\n",
      "  adding: Dockerfile (deflated 18%)\n"
     ]
    }
   ],
   "source": [
    "# ml-api-app.zip 파일 생성\n",
    "!zip -r ml-api-app.zip Main.py model.pkl requirements.txt Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zipfile 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축이 /Users/sindongjun/Desktop/ml-api-app 폴더로 해제되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# 압축 파일 경로 (예: 현재 폴더에 ml-api-app.zip)\n",
    "zip_path = \"/Users/sindongjun/AIOpsNLP/ml-api-app.zip\"\n",
    "\n",
    "# 압축 해제할 위치 (예: Desktop)\n",
    "extract_dir = \"/Users/sindongjun/Desktop/ml-api-app\"\n",
    "\n",
    "# 디렉토리 없으면 생성\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# 압축 해제\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(f\"압축이 {extract_dir} 폴더로 해제되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github Actions 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디렉토리 생성 (숨김폴더)\n",
    "!mkdir -p .github/workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x  2 sindongjun  staff  64 May 26 17:38 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  3 sindongjun  staff  96 May 26 17:38 \u001b[34m..\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# 숨김 폴더 내용 확인\n",
    "!ls -la .github/workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub Actions 워크플로우 파일 생성\n",
    "workflow_code = \"\"\"\n",
    "name: Build and Push Docker Image\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [main]\n",
    "\n",
    "jobs:\n",
    "  build:\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "    - name: Checkout source code\n",
    "      uses: actions/checkout@v2\n",
    "\n",
    "    - name: Set up Docker Buildx\n",
    "      uses: docker/setup-buildx-action@v2\n",
    "\n",
    "    - name: Log in to DockerHub\n",
    "      run: echo \"${{ secrets.DOCKER_PASSWORD }}\" | docker login -u \"${{ secrets.DOCKER_USERNAME }}\" --password-stdin\n",
    "\n",
    "    - name: Build Docker image\n",
    "      run: docker build -t ${{ secrets.DOCKER_USERNAME }}/scalp:latest .\n",
    "\n",
    "    - name: Push Docker image\n",
    "      run: docker push ${{ secrets.DOCKER_USERNAME }}/scalp:latest\n",
    "\n",
    "    - name: Trigger Render Deploy Hook\n",
    "      run: |\n",
    "        curl -X POST ${{ secrets.RENDER_DEPLOY_HOOK }}\n",
    "\n",
    "\"\"\"\n",
    "with open(\".github/workflows/docker-build.yml\", \"w\") as f:\n",
    "    f.write(workflow_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
